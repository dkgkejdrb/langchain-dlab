{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "104b849a",
   "metadata": {},
   "source": [
    "## 복습: Chain의 기본 구조 = 프롬프트 + 모델 + 출력 파서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbe0039",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb79f44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# output_parser 객체 생성\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# prompt_template 객체 생성\n",
    "template = \"{country}의 수도를 알려줘\"\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "\n",
    "# llm 모델 객체 생성\n",
    "llm = ChatOpenAI(model_name='gpt-4o-mini')\n",
    "\n",
    "input = {\n",
    "    'country': '대한민국'\n",
    "}\n",
    "\n",
    "# chain에 output_parser 추가\n",
    "chain = prompt_template | llm | output_parser\n",
    "\n",
    "chain.invoke(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7407b1",
   "metadata": {},
   "source": [
    "## 프롬프트 템플릿에 복수 input_variables를 추가하려면?\n",
    "\n",
    "prompt_template의 input_variables는 리스트로 관리되며, 실제 변수 값은 딕셔너리 형태로 전달하여 주입할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a717e06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_template에 두 개의 input_variables 설정\n",
    "template = \"{country}의 {interests}를 알려줘\"\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1b1c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_variables의 데이터를 딕셔너리로 셋팅\n",
    "input = {\n",
    "    'country': '대한민국',\n",
    "    'interests': '인구'\n",
    "}\n",
    "\n",
    "llm = ChatOpenAI(model_name='gpt-4o-mini', temperature=0.1)\n",
    "\n",
    "chain = prompt_template | llm | output_parser\n",
    "\n",
    "# chain에 input_variables 전달 후 invoke\n",
    "chain.invoke(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a63d606",
   "metadata": {},
   "source": [
    "※ 실습: 나만의 여행 가이드 프롬프트 만들기\n",
    "\n",
    "아래와 같은 문장을 생성하는 PromptTemplate을 작성하고 실행해보시오.\n",
    "\n",
    "+ {city}, {activity} 두 개의 input_variables를 사용하는 템플릿을 만들 것\n",
    "\n",
    "+ \"{도시명}에서 즐길 수 있는 {활동 종류}를 추천해줘.\"\n",
    "\n",
    "    - 예시 문장:\n",
    "\n",
    "      \"부산에서 즐길 수 있는 해양 스포츠를 추천해줘.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c761f597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deac43c5",
   "metadata": {},
   "source": [
    "## 워크플로우 설계 및 구현\n",
    "\n",
    "사용자에게 어떠한 응답을 제공하는 domain 특화 Large-Language-Model(LLM)을 개발하고 싶나요?\n",
    "\n",
    "선생님의 논문에서 개발한 시스템 중, Code Review Module의 워크플로우를 살펴봅시다.\n",
    "\n",
    "### What is a workflow?\n",
    "\n",
    "- A workflow is a system for managing repetitive processes and tasks which occur in a particular order.\n",
    "- LangChain을 활용하면 이러한 워크플로우를 모듈 단위로 분리하고, \n",
    "  \n",
    "  재사용 가능하게 구성할 수 있어 LLM 기반 시스템의 구조적 설계와 유지보수가 쉬워집니다.\n",
    "\n",
    "### What is a domain 특화 LLM?\n",
    "\n",
    "- 의료, 법률, 교육, 소프트웨어 등 특정 분야의 지식과 언어 패턴에 맞춰 튜닝된 LLM을 말합니다.\n",
    "- 일반적인 LLM은 폭넓은 주제를 다룰 수 있지만, \n",
    "\n",
    "  도메인 특화 LLM은 특정 분야의 정확하고 신뢰할 수 있는 응답을 생성하는 데 강점을 가집니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28565179",
   "metadata": {},
   "source": [
    "### 분기 기반 순차 실행으로 정교한 도메인 LLM 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d931bea",
   "metadata": {},
   "source": [
    "다음 링크를 통해, domain 특화 LLM의 한 예시인 선생님이 구현한 **CRM 워크플로우의 구조**를 살펴봅시다.\n",
    "\n",
    "- 링크: https://github.com/dkgkejdrb/CodeTutorBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f422eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRM 중, Review Necessity Chain\n",
    "from dotenv import load_dotenv\n",
    "# API KEY 정보로드\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "RNC_prompt_template = PromptTemplate.from_template(\n",
    "\"\"\"\n",
    "    Before reviewing the [SubmittedCode], determine whether a review is necessary.\n",
    "                \n",
    "    - Respond 'yes' if the [SubmittedCode] contains mistakes or improvements are needed.\n",
    "    - Respond 'no_correct' if the [SubmittedCode] is already correct and matches the [Solution], meaning no review is needed.\n",
    "    - Respond 'no_meaningless' if the [SubmittedCode] is too simple (e.g., 'print()', single numbers, random characters) and does not attempt to solve the [PythonProblem], meaning no review is needed.\n",
    "        \n",
    "    Respond with only one of the three options: 'yes', 'no_correct', or 'no_meaningless'.\n",
    "        \n",
    "    PythonProblem: {pythonProblem}\n",
    "    Submitted Code: {submittedCode}\n",
    "    Solution: {solution}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "RNC_llm = ChatOpenAI( \n",
    "    model_name = \"gpt-4o\",\n",
    "    temperature = 0.2,\n",
    "    max_tokens = 50,\n",
    "    top_p = 0.1\n",
    ")\n",
    "\n",
    "RNC_input = {\n",
    "    'pythonProblem': \"\"\"\n",
    "        [문제]\n",
    "        print() 함수와 sep, end 옵션을 이용하여 \"출력 예시\"와 같이 출력해 봅시다.\n",
    "\n",
    "        [테스트]\n",
    "        입력 예시: \n",
    "        없음\n",
    "\n",
    "        출력 예시:\n",
    "        '코로나 블루', 극복하기!\n",
    "    \"\"\",\n",
    "    'submittedCode': \"\"\"\n",
    "        print(\"'코로나 블루'\",\"극복하기\")\n",
    "    \"\"\",\n",
    "    'solution': \"\"\"\n",
    "        print(\"'코로나 블루'\",\"극복하기\",sep=', ',end=! )\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "RNC = RNC_prompt_template | RNC_llm | output_parser\n",
    "RNC_response = RNC.invoke(RNC_input)\n",
    "print(RNC_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9596516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중요★) 분기RNC_response = yes 인 경우에만 Review Comment Generation Chain 실행\n",
    "if not RNC_response == 'yes': print('코드 리뷰 필요 없음')\n",
    "else:\n",
    "    # CRM 중, Review Comment Generation Chain\n",
    "    RCGC_styleTone = \"\"\"\n",
    "        Review with vocabulary difficulty level that primary and secondary school students can understand.\n",
    "    \"\"\"\n",
    "    RCGC_instruction = \"\"\"\n",
    "        As in the example shown in [Example], [RC][/RC] and [R][/R] must be included in the response. \n",
    "        In [SubmittedCode], add ‘Code to fix’ comment to the end of incorrect code lines.\n",
    "        Reply to [RC][/RC] with commented [SubmittedCode] as is.\n",
    "        Respond to code reviews with [R][/R] in a ‘polite tone’ and within three sentences and emoji.\n",
    "    \"\"\"\n",
    "    RCGC_restriction = \"\"\"\n",
    "        Must never present the fixed code and [Solution] to [RC][/RC] and [R][/R].\n",
    "        Do not include code fences such as \\`\\`\\`python or any similar syntax in your response.\n",
    "    \"\"\"\n",
    "    RCGC_example =\"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    RCGC_prompt_template = PromptTemplate.from_template(\n",
    "        RCGC_styleTone + RCGC_instruction + RCGC_restriction +\n",
    "    \"\"\"\n",
    "        PythonProblem: {pythonProblem}\n",
    "        SubmittedCode: {submittedCode}\n",
    "        Solution: {solution}\n",
    "        Example: {example}\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    RCGC_llm = ChatOpenAI( \n",
    "        model_name = \"gpt-4o\",\n",
    "        temperature = 0.2,\n",
    "        max_tokens = 320,\n",
    "        top_p = 0.8\n",
    "    )\n",
    "\n",
    "    RCGC_input = {\n",
    "        'pythonProblem': \"\"\"\n",
    "            [문제]\n",
    "            print() 함수와 sep, end 옵션을 이용하여 \"출력 예시\"와 같이 출력해 봅시다.\n",
    "\n",
    "            [테스트]\n",
    "            입력 예시: \n",
    "            없음\n",
    "\n",
    "            출력 예시:\n",
    "            '코로나 블루', 극복하기!\n",
    "        \"\"\",\n",
    "        'submittedCode': \"\"\"\n",
    "            print(\"'코로나 블루'\",\"극복하기\")\n",
    "        \"\"\",\n",
    "        'solution': \"\"\"\n",
    "            print(\"'코로나 블루'\",\"극복하기\",sep=', ',end=! )\n",
    "        \"\"\",\n",
    "        'example': \"\"\"\n",
    "            [RC]\n",
    "            length = 42.195\n",
    "            print(\"Marathon’s distence %.fkm\" %length) # Code to fix\n",
    "            print(\"Marathon’s distance is %.2fkm\" %length)\n",
    "            [/RC]\n",
    "\n",
    "            [R]\n",
    "            There is a typo in the print function in the first line. The correct expression is ‘distance’ instead of ‘distence’. Check for typos with a little more attention!\n",
    "            [/R]\n",
    "        \"\"\"\n",
    "    }\n",
    "\n",
    "    RCGC = RCGC_prompt_template | RCGC_llm | output_parser\n",
    "    RCGC_response = RCGC.invoke(RCGC_input)\n",
    "    print(RCGC_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e96622d",
   "metadata": {},
   "source": [
    "※ 실습: 감정 판단 체인 만들기\n",
    "\n",
    "+ 감정 판단 체인 →\n",
    "\t- text가 부정적인 감정이라면 '예', 아니면 '아니오'라고 답변하는 체인\n",
    "\n",
    "\n",
    "+ 분기 처리 →\n",
    "\t- 감정 판단 체인의 응답 결과가 \"예\"일 경우: 다음 체인 실행\n",
    "\t- 감정 판단 체인의 응답 결과가 \"아니오\"일 경우: \"리뷰가 필요하지 않습니다.\" 출력\n",
    "\n",
    "+ 리뷰 생성 체인 →\n",
    "\t- text에서 어떤 부분이 부정적인지 친절하게 알려주는 체인\n",
    "\n",
    "+ {\"text\": \"나는 오늘 너무 피곤하고 지쳤어.\"}를 입력하여 체인을 실행할 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6f81a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac6144b",
   "metadata": {},
   "source": [
    "## Chain을 병렬로 실행할 수 있을까?\n",
    "\n",
    "RunnableParallel을 사용하여, 복수의 chain을 동시에 실행할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3db22d3",
   "metadata": {},
   "source": [
    "### Runnable 이란?\n",
    "Runnable은 LangChain에서 입력을 받아 출력을 생성하는 모든 실행 단위를 의미함.\n",
    "\n",
    "LLM, PromptTemplate, Parser 등 대부분의 LangChain 구성 요소는 Runnable이라고 함.\n",
    "\n",
    "즉, .invoke(input)으로 실행할 수 있는 객체는 전부 Runnable이라고 보면 됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65948672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain 을 구성하는 요소는 전부 Runnable이라 볼 수 있음\n",
    "prompt = PromptTemplate.from_template(\"Translate in Korean: {text}\")\n",
    "# prompt.invoke({'text': \"hello?\"})\n",
    "llm = ChatOpenAI()\n",
    "chain = prompt | llm  # 둘 다 Runnable이기 때문에 체이닝 가능\n",
    "# chain.invoke({'text': \"hello?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce5a4ff",
   "metadata": {},
   "source": [
    "### RunnableParallel을 사용한 chain 병렬 실행 예시 #1\n",
    "\n",
    "- 체인 1: 나라의 수도를 생성\n",
    "- 체인 2: 나라의 인구를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5d466d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "chain1 = PromptTemplate.from_template(\"{country}의 수도는?\") | ChatOpenAI() | output_parser\n",
    "\n",
    "chain2 = PromptTemplate.from_template(\"{country}의 인구?\") | ChatOpenAI() | output_parser\n",
    "\n",
    "combined_chain = RunnableParallel(capital=chain1, populations=chain2)\n",
    "\n",
    "result = combined_chain.invoke({ 'country': '대한민국' })\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23e587f",
   "metadata": {},
   "source": [
    "### RunnableParallel을 사용한 chain 병렬 실행 예시 #2\n",
    "- 체인 1: 검색 가능한 URL을 생성\n",
    "- 체인 2: 해당 주제에 대한 간단한 설명 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537e0ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_prompt = PromptTemplate.from_template(\"'{topic}'에 대해 검색할 수 있는 네이버 검색 URL을 만들어줘.\")\n",
    "url_chain = url_prompt | ChatOpenAI() | output_parser\n",
    "\n",
    "desc_prompt = PromptTemplate.from_template(\"'{topic}'에 대해 초등학생도 이해할 수 있게 설명해줘.\")\n",
    "desc_chain = desc_prompt | ChatOpenAI() | output_parser\n",
    "\n",
    "combined_chain = RunnableParallel(url=url_chain, desc=desc_chain)\n",
    "result = combined_chain.invoke({ 'topic': 'ESG' })\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5b8551",
   "metadata": {},
   "source": [
    "※ 실습: 나만의 여행 정보 병렬 가이드 만들기\n",
    "\n",
    "+ PromptTemplate 1 →\n",
    "    - \"{도시명}의 날씨는 어때?\"\n",
    "        - 예시: \"제주의 날씨는 어때?\"\n",
    "\n",
    "+ PromptTemplate 2 →\n",
    "    - \"{도시명}에서 즐길 수 있는 대표 음식은 뭐야?\"\n",
    "        - 예시: \"제주에서 즐길 수 있는 대표 음식은 뭐야?\"\n",
    "\n",
    "+ 두 PromptTemplate을 각각 LLM과 연결\n",
    "\n",
    "+ RunnableParallel을 사용하여 두 개의 체인을 병렬 실행\n",
    "\n",
    "+ {\"city\": \"제주\"}를 입력하여 두 응답을 동시에 출력할 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9e6b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0ee393",
   "metadata": {},
   "source": [
    "## ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a7f784",
   "metadata": {},
   "source": [
    "ChatPromptTemplate 은 **대화목록을 프롬프트로 주입**하고자 할 때 활용할 수 있음.\n",
    "\n",
    "메시지는 튜플(tuple) 형식으로 구성하며, (role, message) 로 구성하여 리스트로 생성.\n",
    "\n",
    "- Role\n",
    "    + \"system\": 시스템 설정 메시지. 주로 전역설정과 관련된 프롬프트입니다.  \n",
    "    + \"human\" : 사용자 입력 메시지 입니다.\n",
    "    + \"ai\": AI 의 답변 메시지입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22918732",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_template(\"{country}의 수도는 어디인가요?\")\n",
    "chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177df433",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt.format(country=\"대한민국\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9683adc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        # role, message\n",
    "        (\"system\", \"당신은 친절한 AI 어시스턴트입니다. 당신의 이름은 {name} 입니다.\"),\n",
    "        (\"human\", \"반가워요!\"),\n",
    "        (\"ai\", \"안녕하세요! 무엇을 도와드릴까요?\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 챗 message 를 생성합니다.\n",
    "messages = chat_template.format_messages(\n",
    "    name=\"디랩\", user_input=\"당신의 이름은 무엇입니까?\"\n",
    ")\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e085c3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.invoke(messages).content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec7917d",
   "metadata": {},
   "source": [
    "이번에는 체인을 생성해보겠음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e22435f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chat_template | llm\n",
    "\n",
    "chain.invoke({\"name\": \"디랩\", \"user_input\": \"잘 지내십니까?\"}).content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3249a1c4",
   "metadata": {},
   "source": [
    "※ 실습: 나만의 AI 어시스턴트 대화 흐름 만들기\n",
    "\n",
    "+ ChatPromptTemplate.from_messages()를 사용하여 아래의 대화 시나리오를 그대로 구현:\n",
    "\n",
    "    역할\t| 메시지\n",
    "\n",
    "    system\t| 당신은 {user_name}이라는 이름을 가진 공손한 AI 비서입니다.\n",
    "\n",
    "    human\t| 안녕하세요!\n",
    "\n",
    "    ai\t| 안녕하세요. 무엇을 도와드릴까요?\n",
    "\n",
    "    human\t| {question}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "+ ChatOpenAI() 또는 ChatGPT LLM과 연결하여 응답 출력\n",
    "\n",
    "\n",
    "+ invoke()를 사용하여 다음 입력으로 실행해볼 것:\n",
    "\n",
    "    - {\"user_name\": \"도우미봇\", \"question\": \"오늘 날씨 어때?\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3a10c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-dlab-Gk6qnrIK-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
