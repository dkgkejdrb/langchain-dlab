{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "104b849a",
   "metadata": {},
   "source": [
    "## 기본 구조: 프롬프트 + 모델 + 출력 파서\n",
    "\n",
    "가장 기본적인 사용 구조는\n",
    "prompt 템플릿과 모델을 함께 연결하는 것입니다.\n",
    "\n",
    "이것이 어떻게 동작하는지 보기 위해, 각 나라별 수도를 물어보는 Chain을 생성해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf28f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deac43c5",
   "metadata": {},
   "source": [
    "## 프롬프트 템플릿의 활용\n",
    "\n",
    "**PromptTemplate**\n",
    "+ 사용자의 입력 변수를 주입하여 완전한 프롬프트 문자열을 만드는 데 사용되는 템플릿.\n",
    "+ 사용법:\n",
    "    - **template**: 템플릿 문자열. 이 문자열에는 중괄호 {}가 변수를 나타냄.\n",
    "    - **input_variable**: 중괄호 안에 들어갈 변수의 이름을 리스트로 정의.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd24185",
   "metadata": {},
   "source": [
    "### input_variable\n",
    "- input_varaible는 PromptTemplate에서 사용되는 변수의 이름을 정의하는 리스트."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f84684",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897edcae",
   "metadata": {},
   "source": [
    ".from_template() 메소드를 사용하여 PromptTemplate 객체 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b35218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# template 정의\n",
    "template = \"{country}의 수도는 어디인가요?\"\n",
    "\n",
    "# from_template 메소드를 이용하여 PromptTemplate 객체 생성\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6745ee2",
   "metadata": {},
   "source": [
    "이제 PromptTemplate 객체를 사용하여 완전한, Prompt를 생성해보자.\n",
    "\n",
    "만약, PromptTemplate의 input_variables에 값을 주입하지 않는다면?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112d389b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt 생성\n",
    "prompt = prompt_template.format(country='')\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c55b63",
   "metadata": {},
   "source": [
    "PromptTemplate의 input_variables에 값을 주입한 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18685ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt 생성\n",
    "prompt = prompt_template.format(country='대한민국')\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544fcda6",
   "metadata": {},
   "source": [
    "※ 실습: input_variables로 영어 문장으로 받고, 한국어 번역을 요청하는 prompt를 생성하시오.\n",
    "- PromptTemplate 라이브러리 임포트\n",
    "- template 정의\n",
    "    * input_variables: 'en_dialogue'\n",
    "- prompt_template의 input_variables에 다음 영어 문장을 주입하여 prompt 생성\n",
    "    * 'It is only with the heart that one can see rightly; what is essential is invisible to the eye. - My Litte Prince'\n",
    "- prompt 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e382ad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1691050",
   "metadata": {},
   "source": [
    "## Chain 생성\n",
    "LCEL (LangChain Expression Language)\n",
    "![LCEL](https://codetutorbot.blob.core.windows.net/image/LCEL.png)\n",
    "\n",
    "- LCEL을 사용, 구성 요소를 단일 체인으로 결합할 수 있음.\n",
    "\n",
    "### chain's syntax:\n",
    "- chain = prompt | llm | output_parser\n",
    "\n",
    "'|'는 파이프 연산자, 서로 다른 구성 요소를 연결하고 한 구성 요소의 '출력'을 다음 구성 요소의 '입력'으로 전달.\n",
    "\n",
    "### chain's workflow:\n",
    "- input_variables => PromptTemplate 에 전달\n",
    "- PromptTemplate => LLM 에 전달\n",
    "- LLM's generated response => output_parser 에 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5754e363",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 요약을 위한 프롬프트 템플릿 문자열 정의\n",
    "template = \"{text_contents}를 30글자 이내로 요약해줘\"\n",
    "\n",
    "# PromptTemplate 객체 생성\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "\n",
    "# OpenAI의 챗 모델 인스턴스 생성 (기본값은 gpt-3.5-turbo)\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "# 프롬프트 템플릿과 LLM을 파이프 연산자로 연결하여 체인 구성\n",
    "chain = prompt_template | llm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0ef8a0",
   "metadata": {},
   "source": [
    "### invoke() 호출\n",
    "- python 딕셔너리 형태로 입력값을 전달합니다.(키: 값)\n",
    "- invoke() 함수 호출 시, 입력값을 전달합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09cd9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input 딕셔너리에 요약할 문장 저장\n",
    "input = {\n",
    "    'text_contents': '''\n",
    "        A large language model (LLM) is a type of machine learning model designed for natural language processing tasks such as language generation. LLMs are language models with many parameters, and are trained with self-supervised learning on a vast amount of text.\n",
    "\n",
    "        The largest and most capable LLMs are generative pretrained transformers (GPTs). Modern models can be fine-tuned for specific tasks or guided by prompt engineering.[1] These models acquire predictive power regarding syntax, semantics, and ontologies[2] inherent in human language corpora, but they also inherit inaccuracies and biases present in the data they are trained in.\n",
    "        '''\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54edbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt 객체와 model 객체를 파이프(|) 연산자로 연결하고 invoke 메서드를 사용하여 input을 전달\n",
    "# 이를 통해 AI 모델이 생성한 메시지를 반환\n",
    "chain.invoke(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a6207f",
   "metadata": {},
   "source": [
    "※ 실습: input_variables로 topic을 받고, 100글자 이내로 설명하는 chain을 생성하시오.\n",
    "- PromptTemplate, ChatOpenAI 라이브러리 임포트\n",
    "- template 정의\n",
    "    * topic을 설명하기 위한 프롬프트 템플릿 문자열 정의\n",
    "    * input_variables: 'topic'\n",
    "- 챗 모델 인스턴스 생성\n",
    "    * max_tokens: 100\n",
    "    * model_name: gpt-4o-mini\n",
    "- propmpt_template | llm의 chain 생성\n",
    "- chain invoke\n",
    "    * input = {\n",
    "    'topic': '4차 산업 혁명'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e95f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3672f8c",
   "metadata": {},
   "source": [
    "## 출력파서 (Output Parser)\n",
    "출력파서를 이용하면, AIMessage로 받아오는 결과에서 content 부분만 잘라서 가져올 수 있다.\n",
    "\n",
    "편리하기 때문에 사용.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7b9e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3865e5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "# 출력파서 라이브러리 추가\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# output_parser 객체 생성\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "\n",
    "template = \"{text_contents}를 30글자 이내로 요약해줘\"\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "\n",
    "llm = ChatOpenAI(model_name='gpt-4o-mini')\n",
    "\n",
    "input = {\n",
    "    'text_contents': '''\n",
    "        A large language model (LLM) is a type of machine learning model designed for natural language processing tasks such as language generation. LLMs are language models with many parameters, and are trained with self-supervised learning on a vast amount of text.\n",
    "\n",
    "        The largest and most capable LLMs are generative pretrained transformers (GPTs). Modern models can be fine-tuned for specific tasks or guided by prompt engineering.[1] These models acquire predictive power regarding syntax, semantics, and ontologies[2] inherent in human language corpora, but they also inherit inaccuracies and biases present in the data they are trained in.\n",
    "        '''\n",
    "}\n",
    "\n",
    "# chain에 output_parser 추가\n",
    "chain = prompt_template | llm | output_parser\n",
    "\n",
    "chain.invoke(input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c8726e",
   "metadata": {},
   "source": [
    "※ 실습: 다음은 영어회화 포맷을 요청하는 재밌는 예시이다. 해당 코드를 직접 받아 작성하며, chain.invoke() 과정과 다양한 템플릿을 익혀보자.\n",
    "![LCEL_exp](https://codetutorbot.blob.core.windows.net/image/lcelexample.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bef036",
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-dlab-Gk6qnrIK-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
